{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "RANDOM_SEED = 42\n",
    "LABELS = [\"Normal\", \"BANKRUPT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tobin's Q</th>\n",
       "      <th>EPS</th>\n",
       "      <th>Liquidity</th>\n",
       "      <th>Profitability</th>\n",
       "      <th>Productivity</th>\n",
       "      <th>Leverage Ratio</th>\n",
       "      <th>Asset Turnover</th>\n",
       "      <th>Operational Margin</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Market Book Ratio</th>\n",
       "      <th>Assets Growth</th>\n",
       "      <th>Sales Growth</th>\n",
       "      <th>Employee Growth</th>\n",
       "      <th>BK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.943577</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.368583</td>\n",
       "      <td>0.137898</td>\n",
       "      <td>0.040532</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.538394</td>\n",
       "      <td>0.059158</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>-0.022715</td>\n",
       "      <td>0.195206</td>\n",
       "      <td>-0.101516</td>\n",
       "      <td>0.055176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.170303</td>\n",
       "      <td>-0.000979</td>\n",
       "      <td>0.232118</td>\n",
       "      <td>0.129773</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>0.505855</td>\n",
       "      <td>0.057785</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>-0.022708</td>\n",
       "      <td>0.677631</td>\n",
       "      <td>0.167686</td>\n",
       "      <td>1.208515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.675053</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>0.102753</td>\n",
       "      <td>0.131109</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>0.006040</td>\n",
       "      <td>0.373341</td>\n",
       "      <td>0.058470</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>-0.022577</td>\n",
       "      <td>-0.188691</td>\n",
       "      <td>-0.235070</td>\n",
       "      <td>-0.395276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.473397</td>\n",
       "      <td>-0.000573</td>\n",
       "      <td>0.549397</td>\n",
       "      <td>0.129773</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.297050</td>\n",
       "      <td>0.058470</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>-0.022412</td>\n",
       "      <td>0.426924</td>\n",
       "      <td>0.019069</td>\n",
       "      <td>0.093287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.610216</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.403827</td>\n",
       "      <td>0.133804</td>\n",
       "      <td>0.039875</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.390119</td>\n",
       "      <td>0.059848</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>-0.022454</td>\n",
       "      <td>0.209474</td>\n",
       "      <td>0.090797</td>\n",
       "      <td>0.162478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Tobin's Q       EPS  Liquidity  Profitability  Productivity  \\\n",
       "0           1  -0.943577  0.000054   0.368583       0.137898      0.040532   \n",
       "1           2  -1.170303 -0.000979   0.232118       0.129773      0.037908   \n",
       "2           3  -0.675053 -0.000610   0.102753       0.131109      0.037908   \n",
       "3           4  -0.473397 -0.000573   0.549397       0.129773      0.037908   \n",
       "4           5  -0.610216  0.000141   0.403827       0.133804      0.039875   \n",
       "\n",
       "   Leverage Ratio  Asset Turnover  Operational Margin  Return on Equity  \\\n",
       "0        0.009772        0.538394            0.059158          0.003440   \n",
       "1        0.007736        0.505855            0.057785          0.003145   \n",
       "2        0.006040        0.373341            0.058470          0.003178   \n",
       "3        0.001493        0.297050            0.058470          0.003145   \n",
       "4        0.002573        0.390119            0.059848          0.003276   \n",
       "\n",
       "   Market Book Ratio  Assets Growth  Sales Growth  Employee Growth  BK  \n",
       "0          -0.022715       0.195206     -0.101516         0.055176   0  \n",
       "1          -0.022708       0.677631      0.167686         1.208515   0  \n",
       "2          -0.022577      -0.188691     -0.235070        -0.395276   0  \n",
       "3          -0.022412       0.426924      0.019069         0.093287   0  \n",
       "4          -0.022454       0.209474      0.090797         0.162478   0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df=pd.read_csv(\"/Users/monalisa/Downloads/cleaned_data.csv\")\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping passed values \n",
    "cleaned_df.drop([\"Unnamed: 0\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85972, 13)\n",
      "(85972,)\n"
     ]
    }
   ],
   "source": [
    "#Create independent and Dependent Features\n",
    "columns = cleaned_df.columns.tolist()\n",
    "# Filter the columns to remove data we do not want \n",
    "\n",
    "# Filter the columns to remove data we do not want \n",
    "columns = [c for c in columns if c not in [\"BK\"]]\n",
    "# Store the variable we are predicting \n",
    "target = \"BK\"\n",
    "# Define a random state \n",
    "state = np.random.RandomState(42)\n",
    "#X = data[columns]\n",
    "X = cleaned_df[columns]\n",
    "print(X.shape)\n",
    "y=cleaned_df[target]\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting of dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "X_train_SMOTEENN, y_train_SMOTEENN = SMOTEENN(random_state=42).fit_sample(X_train,y_train)\n",
    "#X_val_under, y_val_under = RandomUnderSampler(random_state=42).fit_sample(X_val_std,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "C = np.logspace(0, 4, 10)\n",
    "penalty = [ 'l2']\n",
    "logistic = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0,scoring='roc_auc')\n",
    "best_model = clf.fit(X_train_SMOTEENN, y_train_SMOTEENN)\n",
    "y_pred_Logisticregression=best_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.69      0.81     17084\n",
      "           1       0.02      0.74      0.03       111\n",
      "\n",
      "    accuracy                           0.69     17195\n",
      "   macro avg       0.51      0.71      0.42     17195\n",
      "weighted avg       0.99      0.69      0.81     17195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_Logisticregression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11726,  5358],\n",
       "       [   29,    82]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_Logisticregression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.69\n",
      "Kappa = 0.02\n",
      "F1 Score = 0.03\n",
      "Log Loss = 10.82\n",
      "AUC = 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,cohen_kappa_score,f1_score,log_loss,roc_auc_score\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy_score(y_test, y_pred_Logisticregression)))\n",
    "print(\"Kappa = {:.2f}\".format(cohen_kappa_score(y_test, y_pred_Logisticregression)))\n",
    "print(\"F1 Score = {:.2f}\".format(f1_score(y_test, y_pred_Logisticregression)))\n",
    "print(\"Log Loss = {:.2f}\".format(log_loss(y_test, y_pred_Logisticregression)))\n",
    "print(\"AUC = {:.2f}\".format(roc_auc_score(y_test, y_pred_Logisticregression)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SMOTETomek, y_train_SMOTETomek = SMOTETomek(random_state=42).fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "C = np.logspace(0, 4, 10)\n",
    "penalty = ['l2']\n",
    "logistic = LogisticRegression()\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0,scoring='roc_auc')\n",
    "best_model = clf.fit(X_train_SMOTETomek, y_train_SMOTETomek)\n",
    "y_pred_Logisticregression=best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84     17084\n",
      "           1       0.02      0.72      0.03       111\n",
      "\n",
      "    accuracy                           0.72     17195\n",
      "   macro avg       0.51      0.72      0.44     17195\n",
      "weighted avg       0.99      0.72      0.83     17195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_Logisticregression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12356,  4728],\n",
       "       [   31,    80]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_Logisticregression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.72\n",
      "Kappa = 0.02\n",
      "F1 Score = 0.03\n",
      "Log Loss = 9.56\n",
      "AUC = 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,cohen_kappa_score,f1_score,log_loss,roc_auc_score\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy_score(y_test, y_pred_Logisticregression)))\n",
    "print(\"Kappa = {:.2f}\".format(cohen_kappa_score(y_test, y_pred_Logisticregression)))\n",
    "print(\"F1 Score = {:.2f}\".format(f1_score(y_test, y_pred_Logisticregression)))\n",
    "print(\"Log Loss = {:.2f}\".format(log_loss(y_test, y_pred_Logisticregression)))\n",
    "print(\"AUC = {:.2f}\".format(roc_auc_score(y_test, y_pred_Logisticregression)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE, ADASYN\n",
    "X_train_BorderlineSMOTE, y_train_BorderlineSMOTE = BorderlineSMOTE(random_state=42).fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "C = np.logspace(0, 4, 10)\n",
    "penalty = ['l2']\n",
    "logistic = LogisticRegression()\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "best_model = clf.fit(X_train_BorderlineSMOTE, y_train_BorderlineSMOTE)\n",
    "y_pred_Logisticregression=best_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94     17084\n",
      "           1       0.03      0.58      0.06       111\n",
      "\n",
      "    accuracy                           0.89     17195\n",
      "   macro avg       0.52      0.73      0.50     17195\n",
      "weighted avg       0.99      0.89      0.94     17195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_Logisticregression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15226,  1858],\n",
       "       [   47,    64]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_Logisticregression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.89\n",
      "Kappa = 0.05\n",
      "F1 Score = 0.06\n",
      "Log Loss = 3.83\n",
      "AUC = 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,cohen_kappa_score,f1_score,log_loss,roc_auc_score\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy_score(y_test, y_pred_Logisticregression)))\n",
    "print(\"Kappa = {:.2f}\".format(cohen_kappa_score(y_test, y_pred_Logisticregression)))\n",
    "print(\"F1 Score = {:.2f}\".format(f1_score(y_test, y_pred_Logisticregression)))\n",
    "print(\"Log Loss = {:.2f}\".format(log_loss(y_test, y_pred_Logisticregression)))\n",
    "print(\"AUC = {:.2f}\".format(roc_auc_score(y_test, y_pred_Logisticregression)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ADASYN, y_train_ADASYN = ADASYN(random_state=42).fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "C = np.logspace(0, 4, 10)\n",
    "penalty = ['l2']\n",
    "logistic = LogisticRegression()\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "best_model = clf.fit(X_train_ADASYN, y_train_ADASYN)\n",
    "y_pred_Logisticregression=best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83     17084\n",
      "           1       0.02      0.73      0.03       111\n",
      "\n",
      "    accuracy                           0.71     17195\n",
      "   macro avg       0.51      0.72      0.43     17195\n",
      "weighted avg       0.99      0.71      0.83     17195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_Logisticregression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.71\n",
      "Kappa = 0.02\n",
      "F1 Score = 0.03\n",
      "Log Loss = 9.98\n",
      "AUC = 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,cohen_kappa_score,f1_score,log_loss,roc_auc_score\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy_score(y_test, y_pred_Logisticregression)))\n",
    "print(\"Kappa = {:.2f}\".format(cohen_kappa_score(y_test, y_pred_Logisticregression)))\n",
    "print(\"F1 Score = {:.2f}\".format(f1_score(y_test, y_pred_Logisticregression)))\n",
    "print(\"Log Loss = {:.2f}\".format(log_loss(y_test, y_pred_Logisticregression)))\n",
    "print(\"AUC = {:.2f}\".format(roc_auc_score(y_test, y_pred_Logisticregression)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "C = np.logspace(0, 4, 10)\n",
    "penalty = ['l2']\n",
    "logistic = LogisticRegression()\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "best_model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
